{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofiacompagnoni/interestUSI/blob/main/Assignment1ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiorgiaAuroraAdorni/ML-bachelor-course-assignments-sp23/blob/main/assignment%201/deliverable/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ZPbfVR0ERAzB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsllEQNCRAzH"
      },
      "source": [
        "# Assignment 1\n",
        "Student: Sofia Compagnoni\n",
        "\n",
        "--- \n",
        "# IMPORTANT: all the submitted code should be in 2 cells\n",
        "1) How you trained, evaluated and saved your model\n",
        "2) How to load your model from a file, load the data and evaluate the model. Cell 2) should be running independently (even if cell 1 is not run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVTJbkReRAzI",
        "outputId": "00309422-132a-4e9b-d967-550262e44b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.91981894 0.28059897]\n",
            " [2.63634368 1.62935366]\n",
            " [0.58107833 4.64420079]\n",
            " [4.59640668 2.3688777 ]\n",
            " [4.06567427 3.55362318]]\n",
            "train_data shape: (1400, 2) (1400,)\n",
            "test_data shape: (600, 2) (600,)\n",
            "Parameters: [ 1.3236108  -0.05958542 -0.57665406  0.4393116   0.04132068]\n",
            "MSE test Linear regression: 0.6804349242489404\n",
            "MSE train Linear regression: 0.7264846428520856\n",
            "MSE test poly: 0.4633805024103428\n",
            "MSE train poly: 0.4943805577461204\n",
            "The difference between the MSEs is not statistically significant\n",
            "19/19 [==============================] - 0s 970us/step\n",
            "MSE:  0.014742092058230778\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np \n",
        "from sklearn.metrics import mean_squared_error   \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error   \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression  \n",
        "from scipy.stats import ttest_rel     \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense  \n",
        "import pickle\n",
        "\n",
        "# Load data \n",
        "data = np.load(\"data.npz\")\n",
        "\n",
        "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
        "x = data['x']\n",
        "\n",
        "# y is a Numpy array of shape (n_samples, ) with the targets\n",
        "y = data['y']\n",
        "\n",
        "# Check\n",
        "print(x[:5])\n",
        "\n",
        "# Split data into train and test\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, shuffle=True, random_state=1)\n",
        "print('train_data shape:', x_train.shape, y_train.shape)\n",
        "print('test_data shape:', x_test.shape, y_test.shape)\n",
        "\n",
        "# T1\n",
        "\n",
        "X = np.column_stack((np.ones_like(x_train[:, 0]), x_train[:, 0], x_train[:, 1], np.sin(x_train[:, 1]), x_train[:, 0] * x_train[:, 1]))\n",
        "\n",
        "theta_hat = np.linalg.lstsq(X, y_train, rcond=None)[0]\n",
        "print('Parameters:',theta_hat)\n",
        "\n",
        "# Define the model (linearregression) f(x, theta)\n",
        "def linearregression(x, theta):\n",
        "    y = theta[0] + theta[1] * x[:, 0] + theta[2] * x[:, 1] + theta[3] * np.sin(x[:, 1]) + theta[4] * x[:, 0] * x[:, 1]\n",
        "    return y\n",
        "\n",
        "test_pred_lr = linearregression(x_test, theta_hat)\n",
        "mse = mean_squared_error(y_test, test_pred_lr)\n",
        "print('MSE test Linear regression:', mse)\n",
        "\n",
        "train_pred_lr = linearregression(x_train, theta_hat)\n",
        "mse1 = mean_squared_error(y_train, train_pred_lr)\n",
        "print('MSE train Linear regression:', mse1)\n",
        "\n",
        "with open('modelT1.pkl','wb') as f:\n",
        "  pickle.dump(linearregression,f)\n",
        "\n",
        "# T2\n",
        "\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "x_train_poly = poly.fit_transform(x_train)\n",
        "x_test_poly = poly.transform(x_test)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_train_poly, y_train)\n",
        "\n",
        "pred_test_poly = model.predict(x_test_poly)\n",
        "mse2 = mean_squared_error(y_test, pred_test_poly)\n",
        "\n",
        "pred_train_poly = model.predict(x_train_poly)\n",
        "mse3 = mean_squared_error(y_train, pred_train_poly)\n",
        "\n",
        "print('MSE test poly:', mse2)\n",
        "print('MSE train poly:', mse3)\n",
        "\n",
        "# T-test\n",
        "\n",
        "t_statistic, p_value = ttest_rel(pred_test_poly, test_pred_lr)\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference between the MSEs is statistically significant\")\n",
        "else:\n",
        "    print(\"The difference between the MSEs is not statistically significant\")\n",
        "\n",
        "with open('modelT2.pkl','wb') as f:\n",
        "  pickle.dump(poly,f)\n",
        "\n",
        "# T3 (Bonus)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=x_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "model.fit(x_train, y_train, validation_split=0.2, epochs=280, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_nn = model.predict(x_test)\n",
        "mse4 = mean_squared_error(y_test, y_pred_nn)\n",
        "\n",
        "print('MSE: ', mse4)\n",
        "\n",
        "with open('modelT3.pkl','wb') as f:\n",
        "  pickle.dump(model,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvaDxUkvRAzL"
      },
      "source": [
        "# Example on how to use baseline model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aia-EF56RAzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96002618-17fa-466c-9671-434ad6aac744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "MSE on whole dataset: 0.014962979877481967\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pickle\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates the mean squared error between the values in y_true and the values\n",
        "    in y_pred.\n",
        "    ### YOU CAN NOT EDIT THIS FUNCTION ###\n",
        "    :param y_true: Numpy array, the true target values from the test set;\n",
        "    :param y_pred: Numpy array, the values predicted by your model.\n",
        "    :return: float, the mean squared error between the two arrays.\n",
        "    \"\"\"\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "\n",
        "def load_model(filename):\n",
        "\n",
        "    with open(filename, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load the data\n",
        "# Load data \n",
        "data = np.load(\"data.npz\")\n",
        "\n",
        "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
        "x = data['x']\n",
        "\n",
        "# y is a Numpy array of shape (n_samples, ) with the targets\n",
        "y = data['y']\n",
        "\n",
        "# Load the trained model\n",
        "model_path = './modelT3.pkl'\n",
        "model = load_model(model_path)\n",
        "\n",
        "y = y.reshape(-1,1)\n",
        "\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "\n",
        "############################################################################\n",
        "# STOP EDITABLE SECTION: do not modify anything below this point.\n",
        "############################################################################\n",
        "\n",
        "# Evaluate the prediction using MSE\n",
        "mse = evaluate_predictions(y_pred, y)\n",
        "print(f'MSE on whole dataset: {mse}')\n",
        "\n",
        "# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\n",
        "# DO IT AND EVERYTHING RUNS SMOOTH\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}